{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting urllib3<3,>=1.26 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi>=2021.10.8 (from selenium)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /opt/homebrew/anaconda3/envs/crawling/lib/python3.13/site-packages (from selenium) (4.12.2)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting idna (from trio~=0.17->selenium)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sortedcontainers, websocket-client, urllib3, sniffio, pysocks, idna, h11, certifi, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-24.2.0 certifi-2024.8.30 h11-0.14.0 idna-3.10 outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.25.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.26.2 trio-websocket-0.11.1 urllib3-2.2.3 websocket-client-1.8.0 wsproto-1.2.0\n",
      "zsh:1: command not found: apt-get\n",
      "zsh:1: command not found: apt\n",
      "cp: /usr/lib/chromium-browser/chromedriver: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!apt-get update\n",
    "!apt install chromium-chromedriver\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "!pip install webdriver_manager\n",
    "!pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "options = ChromeOptions()\n",
    "#user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\"\n",
    "#options.add_argument('user-agent=' + user_agent)\n",
    "options.add_argument(\"lang=ko_KR\")\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size=1920x1080')\n",
    "options.add_argument(\"disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "        \n",
    "# 크롬 드라이버 최신 버전 설정\n",
    "service = ChromeService(executable_path=ChromeDriverManager().install(), options=options)\n",
    "\n",
    "# chrome driver\n",
    "driver = webdriver.Chrome(service=service, options=options) # <- options로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '[Publishing Platform Div.] Data Infra Engineer (10년 이상)', 'company_name': '(주)크래프톤', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/191174?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': 'AI Data Scientist', 'company_name': 'SAP코리아(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/190539?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': 'Developer for SAP HANA - Cloud Database Federation to Large Data', 'company_name': 'SAP코리아(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/189907?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': '스마트팩토리 솔루션/서비스 데이터 아키텍트', 'company_name': '현대오토에버(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/189970?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-6', 'platform_name': 'remember'}\n",
      "{'title': '지도2D, 3D 데이터 구축 및 운영 관리', 'company_name': '현대오토에버(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/190020?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-6', 'platform_name': 'remember'}\n",
      "{'title': '보안데이터 기반 인사이트 발굴', 'company_name': '현대오토에버(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/187974?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-6', 'platform_name': 'remember'}\n",
      "{'title': 'CP 데이터 품질 관리', 'company_name': '현대오토에버(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/188167?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-6', 'platform_name': 'remember'}\n",
      "{'title': '보안 데이터/통계 시스템 개발', 'company_name': '현대오토에버(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/188005?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-6', 'platform_name': 'remember'}\n",
      "{'title': 'Technical Support Engineering - Microsoft Fabric (Synapse Data Warehouse)', 'company_name': '한국마이크로소프트(유)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/188619?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': '데이터센터 네트웍 구축/운영', 'company_name': '현대오토에버(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/187966?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-6', 'platform_name': 'remember'}\n",
      "{'title': '길안내/교통정보 데이터 분석 및 평가', 'company_name': '현대오토에버(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/188092?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-6', 'platform_name': 'remember'}\n",
      "{'title': '침해위협 판별_빅데이터 기반', 'company_name': '현대오토에버(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/187976?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-6', 'platform_name': 'remember'}\n",
      "{'title': '빅데이터 기반 플랫폼 개발', 'company_name': '현대오토에버(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/187648?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-6', 'platform_name': 'remember'}\n",
      "{'title': '내비게이션 데이터 분석 시스템 개발 및 운영', 'company_name': '현대오토에버(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/188091?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-6', 'platform_name': 'remember'}\n",
      "{'title': '[Associate] Business Transformation Consultant (Data) - IBM Consulting in Seoul, South Korea', 'company_name': '한국IBM(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/187822?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': '[AI] Junior/Senior Research Scientist - Data-centric AI (2년~7년)', 'company_name': '(주)크래프톤', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/180390?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': 'Cloud Technical Solutions Engineer, Data (Korean, English)', 'company_name': '구글코리아(유)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/177755?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': '[HYBE] 데이터 사이언티스트 (마케팅, Data Scientist)', 'company_name': '(주)하이브', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/176190?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': 'Azure Data & AI Solution Sales Specialist', 'company_name': '한국마이크로소프트(유)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/174229?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': 'Commissioning Manager – South Korea (Data Center)', 'company_name': '한국마이크로소프트(유)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/173268?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': 'Director, Data Science', 'company_name': '비자인터내셔날아시아퍼시픽코리아(주)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/164917?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': 'Data Center Inventory & Asset Technician', 'company_name': '한국마이크로소프트(유)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/163479?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': '[HYBE IPX] 응원봉 연출 데이터 제작', 'company_name': '(주)하이브', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/163205?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': '[Weverse Company] 데이터 사이언티스트', 'company_name': '(주)하이브', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/162749?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': 'Technology Specialist (Data & AI)', 'company_name': '한국마이크로소프트(유)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/135456?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': 'Data Center Project Manager', 'company_name': '한국마이크로소프트(유)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/135447?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': 'Data Center Inventory & Asset Technician', 'company_name': '한국마이크로소프트(유)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/135431?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "{'title': '24년 하반기 Data & AI Analytics 컨설턴트 경력직 채용', 'company_name': '딜로이트컨설팅(유)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/132523?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': 'D-46', 'platform_name': 'remember'}\n",
      "{'title': 'Data Center Technician', 'company_name': '구글코리아(유)', 'detail_url': 'https://career.rememberapp.co.kr/job/postings/127334?curationLocation=job_posting_tab&channel=ad_job_postings&jdViewSource=ad_job_postings', 'end_date': '채용 시 마감', 'platform_name': 'remember'}\n",
      "CSV 파일이 성공적으로 저장되었습니다: /Users/youyoungcheon/Desktop/django-project/crawling/remember_job_list.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "# 크롤링할 사이트 URL\n",
    "url = \"https://career.rememberapp.co.kr/job/board/hiring-postings?seed=92987327&search=%7B%22leaderPosition%22%3Afalse%2C%22organizationType%22%3A%22all%22%2C%22applicationType%22%3A%22all%22%2C%22keywords%22%3A%5B%22%EB%8D%B0%EC%9D%B4%ED%84%B0%22%5D%7D\"\n",
    "driver.get(url)\n",
    "\n",
    "# 페이지 로딩 대기\n",
    "time.sleep(3)\n",
    "\n",
    "# 페이지의 HTML 내용 가져오기\n",
    "page_source = driver.page_source\n",
    "\n",
    "# BeautifulSoup로 HTML 파싱\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# 페이지 소스 가져오기\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# 공고 정보 추출\n",
    "job_list = soup.find_all('li', class_='sc-45abcaef-0')\n",
    "\n",
    "# 추출한 데이터 저장을 위한 리스트\n",
    "jobs = []\n",
    "\n",
    "base_url = \"https://career.rememberapp.co.kr\"\n",
    "\n",
    "for job in job_list:\n",
    "    # 공고제목\n",
    "    title = job.find('div', class_='sc-45abcaef-6').text.strip() if job.find('div', class_='sc-45abcaef-6') else 'null'\n",
    "    \n",
    "    # 회사이름\n",
    "    company_name = job.find('div', class_='sc-45abcaef-7').text.strip() if job.find('div', class_='sc-45abcaef-7') else 'null'\n",
    "    \n",
    "    #디테일 페이지로 가는 주소\n",
    "    detail_url = job.find('a', class_='sc-567718ed-0 jzTeOc')['href'] if job.find('a', class_='sc-567718ed-0 jzTeOc') else ''\n",
    "    detail_url = base_url + detail_url if detail_url else ''\n",
    "    # 등록일\n",
    "    end_date = job.find('div', class_='sc-db17a579-0').text.strip() if job.find('div', class_='sc-db17a579-0') else 'null'\n",
    "    \n",
    "    # 출처 (URL)\n",
    "    platform_name = 'remember'\n",
    "\n",
    "    # 데이터 리스트에 추가\n",
    "    jobs.append({\n",
    "        'title': title,\n",
    "        'company_name': company_name,\n",
    "        'detail_url': detail_url,\n",
    "        'end_date': end_date,\n",
    "        'platform_name': platform_name\n",
    "    })\n",
    "\n",
    "# 크롤링한 데이터 출력\n",
    "for job in jobs:\n",
    "    print(job)\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n",
    "# CSV 파일로 저장\n",
    "csv_file = \"/Users/youyoungcheon/Desktop/django-project/crawling/remember_job_list.csv\"\n",
    "csv_columns = ['title', 'company_name', 'detail_url', 'end_date', 'platform_name']\n",
    "\n",
    "try:\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for job in jobs:\n",
    "            writer.writerow(job)\n",
    "    print(f\"CSV 파일이 성공적으로 저장되었습니다: {csv_file}\")\n",
    "except IOError:\n",
    "    print(\"CSV 파일을 저장하는 중에 오류가 발생했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 페이지 크롤링 완료\n",
      "2 페이지 크롤링 완료\n",
      "3 페이지 크롤링 완료\n",
      "4 페이지 크롤링 완료\n",
      "5 페이지 크롤링 완료\n",
      "6 페이지 크롤링 완료\n",
      "7 페이지 크롤링 완료\n",
      "8 페이지 크롤링 완료\n",
      "9 페이지 크롤링 완료\n",
      "10 페이지 크롤링 완료\n",
      "11 페이지 크롤링 완료\n",
      "12 페이지 크롤링 완료\n",
      "13 페이지 크롤링 완료\n",
      "14 페이지 크롤링 완료\n",
      "15 페이지 크롤링 완료\n",
      "16 페이지 크롤링 완료\n",
      "17 페이지 크롤링 완료\n",
      "18 페이지 크롤링 완료\n",
      "19 페이지 크롤링 완료\n",
      "20 페이지 크롤링 완료\n",
      "21 페이지 크롤링 완료\n",
      "22 페이지 크롤링 완료\n",
      "23 페이지 크롤링 완료\n",
      "24 페이지 크롤링 완료\n",
      "25 페이지 크롤링 완료\n",
      "26 페이지 크롤링 완료\n",
      "27 페이지 크롤링 완료\n",
      "CSV 파일 저장 완료: 'peoplenjob_job_list.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# CSV 파일 작성 준비\n",
    "with open('/Users/youyoungcheon/Desktop/django-project/crawling/peoplenjob_job_list.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # CSV 파일 헤더 작성\n",
    "    writer.writerow(['title', 'company_name', 'detail_url', 'end_date', 'platform_name'])\n",
    "\n",
    "    # 여러 페이지 크롤링\n",
    "    for page in range(1, 28):  # 페이지 번호는 원하는 만큼 조정 (예: 1~5페이지)\n",
    "        url = f'https://www.peoplenjob.com/jobs?field=all&q=%EB%8D%B0%EC%9D%B4%ED%84%B0&page={page}'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        rows = soup.find_all('tr')\n",
    "\n",
    "        # 각 공고에서 필요한 정보 추출 및 CSV에 기록\n",
    "        for row in rows:\n",
    "            # 공고 제목\n",
    "            title_tag = row.find('td', class_='job-title')\n",
    "            title = title_tag.find('a').text.strip() if title_tag else 'N/A'\n",
    "\n",
    "            # 회사 이름\n",
    "            company_tag = row.find('td', class_='name')\n",
    "            company_name = company_tag.find('a').text.strip() if company_tag else 'N/A'\n",
    "\n",
    "            # 상세 페이지 URL\n",
    "            detail_url_tag = title_tag.find('a') if title_tag else None\n",
    "            detail_url = f\"{detail_url_tag['href']}\" if detail_url_tag else 'N/A'\n",
    "\n",
    "            # 마감일\n",
    "            end_date_tag = row.find('span', class_='job-fin-date')\n",
    "            end_date = end_date_tag.text.strip() if end_date_tag else 'N/A'\n",
    "\n",
    "            # 출처 (플랫폼 이름)\n",
    "            platform_name = 'peoplenjob'\n",
    "\n",
    "            # CSV 파일에 작성\n",
    "            writer.writerow([title, company_name, detail_url, end_date, platform_name])\n",
    "\n",
    "        print(f\"{page} 페이지 크롤링 완료\")\n",
    "\n",
    "print(\"CSV 파일 저장 완료: 'peoplenjob_job_list.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
